{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangle\n",
    "import explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Web-Scraping GitHub with Beautiful Soup\n",
    "***\n",
    "\n",
    "***1. Identify HTML target feature using Beautiful Soup***\n",
    "\n",
    "`Repo README.md text` - soup.select('article', class_=\"markdown-body entry-content container-lg\")[0].text\n",
    "\n",
    "`Repo primary language` - soup.select('li.d-inline:nth-child(1) > a:nth-child(1)')[0].text\n",
    "\n",
    "***2. Code extraction functions used to create corpus***\n",
    "\n",
    "`def get_soup()`\n",
    "This function takes in a URL, parses the HTML and returns a BeautifulSoup object\n",
    "\n",
    "`def gethub_geology_urls()`\n",
    "This function returns a list of URLs that can be read in the get_readme_articles() function\n",
    "\n",
    "`def get_geo_results()`\n",
    "This function scrapes and returns a list of repo URLs from search results\n",
    "\n",
    "#### Explanation:\n",
    "\n",
    "Using the python library, Beautiful Soup, the README.md text of 507 GitHub repositories were scraped. I focused my search exclusively on repositories identifed by the keyword'Geology'. The results of this scrape were saved in a json file and were used as our research corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df, column):\n",
    "    df['content_clean'] = df[column].apply(basic_clean)\\\n",
    "                                    .apply(tokenize)\\\n",
    "                                    .apply(lemmatize)\\\n",
    "                                    .apply(remove_stopwords)\\\n",
    "                                    .apply(remove_extra_words)\n",
    "\n",
    "    # add a column with a list of words\n",
    "    words = [re.sub(r'([^a-z0-9\\s]|\\s.\\s)', '', doc).split() for doc in df.content_clean]\n",
    "\n",
    "    # column name will be words, and the column will contain lists of the words in each doc\n",
    "    df = pd.concat([df, pd.DataFrame({'words': words})], axis=1)\n",
    "\n",
    "    # add column with number of words in readme content\n",
    "    df['doc_length'] = [len(wordlist) for wordlist in df.words]\n",
    "    \n",
    "    # Adds column with bigrams and trigrams\n",
    "    df['bigrams'] =  df['text_filtered'].apply(lambda row: list(nltk.bigrams(row.split(' '))))\n",
    "    df['trigrams'] =  df['text_filtered'].apply(lambda row: list(nltk.trigrams(row.split(' '))))\n",
    "    \n",
    "    # Specify dataframe content\n",
    "    df = df[['language','content','content_clean','doc_length','words','bigrams','trigrams']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Explanation:\n",
    "\n",
    "`basic_clean( ):` This function changes the text to lowercase, removes special characters, encodes to ascii and recode to utf-8 to remove numbers from the text, and finally replaces anything that is not a letter, number, whitespace, or a single quote with an empty string. \n",
    "\n",
    "`tokenize( ):` This function takes in a string and returns that string broken up in to a list of individual words.\n",
    "\n",
    "`lemmatize( ):` This function takes in string for and returns a string with words simplified to dictionary roots.\n",
    "\n",
    "`remove_stopwords():` This function is a spealized cleaning tool from the Gensim library that cleans and parses \n",
    "                      text for topic modeling and removes more common words then the traditional nltk library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural Language ToolKit (NLTK)\n",
    "\n",
    "-NLTK library has 179 words in the stopword collection.\n",
    "\n",
    "Note: All the words in the default libraryâ€™s stopword list are in lower case, that means documents/sentences words also must be lower case. Otherwise, stopword not got removed from your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text : The first time I saw Catherine she was wearing a vivid crimson dress and was nervously leafing through a magazine in my waiting room.\n",
      "Text without stopwords : first time saw Catherine wearing vivid crimson dress nervously leafing magazine waiting room.\n",
      "Total count of stopwords in NLTK is 179\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "text = f\"The first time I saw Catherine she was wearing a vivid crimson dress and was nervously \" \\\n",
    "f\"leafing through a magazine in my waiting room.\"\n",
    "text_without_stopword = [word for word in text.split() if word.lower() not in nltk_stopwords]\n",
    "print(f\"Original Text : {text}\")\n",
    "print(f\"Text without stopwords : {' '.join(text_without_stopword)}\")\n",
    "print(f\"Total count of stopwords in NLTK is {len(nltk_stopwords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim Library\n",
    "\n",
    "-Gensim has 337 words in their stopwords collection\n",
    "\n",
    "Note: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text : The first time I saw Catherine she was wearing a vivid crimson dress and was nervously leafing through a magazine in my waiting room.\n",
      "Text without stopwords : time saw catherine wearing vivid crimson dress nervously leafing magazine waiting room.\n",
      "Total count of stopwords in Ginsim is 337\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import gensim\n",
    "\n",
    "gensim_stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
    "\n",
    "text = f\"The first time I saw Catherine she was wearing a vivid crimson dress and was nervously \" \\\n",
    "       f\"leafing through a magazine in my waiting room.\"\n",
    "\n",
    "print(f\"Original Text : {text}\")\n",
    "print(f\"Text without stopwords : {remove_stopwords(text.lower())}\")\n",
    "print(f\"Total count of stopwords in Ginsim is {len(gensim_stopwords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration: (Topic Modeling)\n",
    "\n",
    "1. Create LDA Object\n",
    "2. Fit to content\n",
    "3. Use LDA to predict (n) Topics\n",
    "4. Explore topics for correlations\n",
    "5. Repeat and fine tune model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call in Clean Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>words</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python</td>\n",
       "      <td>Map Merger tool - tested using ArcMap 10.7\\nWr...</td>\n",
       "      <td>map merger tool tested arcmap written ryan cro...</td>\n",
       "      <td>38</td>\n",
       "      <td>[map, merger, tool, tested, arcmap, written, r...</td>\n",
       "      <td>[(map, merger), (merger, tool), (tool, tested)...</td>\n",
       "      <td>[(map, merger, tool), (merger, tool, tested), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>wellio.js\\nJavaScript for converting well-log ...</td>\n",
       "      <td>welliojs javascript converting welllog standar...</td>\n",
       "      <td>1053</td>\n",
       "      <td>[welliojs, javascript, converting, welllog, st...</td>\n",
       "      <td>[(welliojs, javascript), (javascript, converti...</td>\n",
       "      <td>[(welliojs, javascript, converting), (javascri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>geomodel-2-3dweb\\n\\nGenerates 3D web versions ...</td>\n",
       "      <td>geomodeldweb generates d web version geologica...</td>\n",
       "      <td>152</td>\n",
       "      <td>[geomodeldweb, generatesweb, version, geologic...</td>\n",
       "      <td>[(geomodeldweb, generates), (generates, d), (d...</td>\n",
       "      <td>[(geomodeldweb, generates, d), (generates, d, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>GeoFeature\\nGeological features of the Quanfoc...</td>\n",
       "      <td>geofeature geological feature quanfock hill de...</td>\n",
       "      <td>166</td>\n",
       "      <td>[geofeature, geological, feature, quanfock, hi...</td>\n",
       "      <td>[(geofeature, geological), (geological, featur...</td>\n",
       "      <td>[(geofeature, geological, feature), (geologica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>U.S. Geological Survey Best Practices\\nThis re...</td>\n",
       "      <td>u geological survey best practice repository h...</td>\n",
       "      <td>13</td>\n",
       "      <td>[u, geological, survey, best, practice, reposi...</td>\n",
       "      <td>[(u, geological), (geological, survey), (surve...</td>\n",
       "      <td>[(u, geological, survey), (geological, survey,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           language                                            content  \\\n",
       "0            Python  Map Merger tool - tested using ArcMap 10.7\\nWr...   \n",
       "1  Jupyter Notebook  wellio.js\\nJavaScript for converting well-log ...   \n",
       "2            Python  geomodel-2-3dweb\\n\\nGenerates 3D web versions ...   \n",
       "3        JavaScript  GeoFeature\\nGeological features of the Quanfoc...   \n",
       "4        JavaScript  U.S. Geological Survey Best Practices\\nThis re...   \n",
       "\n",
       "                                       content_clean  doc_length  \\\n",
       "0  map merger tool tested arcmap written ryan cro...          38   \n",
       "1  welliojs javascript converting welllog standar...        1053   \n",
       "2  geomodeldweb generates d web version geologica...         152   \n",
       "3  geofeature geological feature quanfock hill de...         166   \n",
       "4  u geological survey best practice repository h...          13   \n",
       "\n",
       "                                               words  \\\n",
       "0  [map, merger, tool, tested, arcmap, written, r...   \n",
       "1  [welliojs, javascript, converting, welllog, st...   \n",
       "2  [geomodeldweb, generatesweb, version, geologic...   \n",
       "3  [geofeature, geological, feature, quanfock, hi...   \n",
       "4  [u, geological, survey, best, practice, reposi...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(map, merger), (merger, tool), (tool, tested)...   \n",
       "1  [(welliojs, javascript), (javascript, converti...   \n",
       "2  [(geomodeldweb, generates), (generates, d), (d...   \n",
       "3  [(geofeature, geological), (geological, featur...   \n",
       "4  [(u, geological), (geological, survey), (surve...   \n",
       "\n",
       "                                            trigrams  \n",
       "0  [(map, merger, tool), (merger, tool, tested), ...  \n",
       "1  [(welliojs, javascript, converting), (javascri...  \n",
       "2  [(geomodeldweb, generates, d), (generates, d, ...  \n",
       "3  [(geofeature, geological, feature), (geologica...  \n",
       "4  [(u, geological, survey), (geological, survey,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wrangle.get_geo_results(cached=True)\n",
    "df = wrangle.prep_data(df, 'content')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling: Step One (Applying LDA)\n",
    "\n",
    "Before we can apply LDA, we need to create vocabulary of all the words in our data. Remember from the previous article, we could do so with the help of a count vectorizer.\n",
    "\n",
    "sklearn.feature_extraction.text module to create a document-term matrix. We specify to only include those words that appear in less than 80% of the document and appear in at least 2 documents. We also remove all the stop words as they do not really contribute to topic modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.decomposition import LatentDirichletAllocation\n",
    "# import random\n",
    "\n",
    "# def nlp_topic_modeling(df, max_df, min_df, n_components):\n",
    "#     count_vect = CountVectorizer(max_df=max_df, min_df=min_df, stop_words='english')\n",
    "#     doc_term_matrix = count_vect.fit_transform(df['content_clean'].values.astype('U'))\n",
    "#     LDA = LatentDirichletAllocation(n_components=n_components, random_state=123)\n",
    "#     LDA.fit(doc_term_matrix)\n",
    "#     for i,topic in enumerate(LDA.components_):\n",
    "#         print(f'Top {n_components} words for topic #{i}:')\n",
    "#         print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "#         print('\\n')\n",
    "#     topic_values = LDA.transform(doc_term_matrix)\n",
    "#     df['Topic'] = topic_values.argmax(axis=1)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words for topic #0:\n",
      "['geological', 'usgs', 'text', 'report', 'set', 'project', 'earthquake', 'file', 'map', 'data']\n",
      "\n",
      "\n",
      "Top 5 words for topic #1:\n",
      "['example', 'code', 'geological', 'geology', 'version', 'python', 'run', 'model', 'data', 'file']\n",
      "\n",
      "\n",
      "Top 5 words for topic #2:\n",
      "['line', 'package', 'notebook', 'powerlaw', 'exercise', 'deposit', 'pip', 'conda', 'python', 'install']\n",
      "\n",
      "\n",
      "Top 5 words for topic #3:\n",
      "['code', 'app', 'project', 'npm', 'test', 'build', 'use', 'run', 'file', 'enabled']\n",
      "\n",
      "\n",
      "Top 5 words for topic #4:\n",
      "['earthquake', 'usgs', 'file', 'build', 'use', 'geological', 'project', 'app', 'android', 'license']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>words</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python</td>\n",
       "      <td>Map Merger tool - tested using ArcMap 10.7\\nWr...</td>\n",
       "      <td>map merger tool tested arcmap written ryan cro...</td>\n",
       "      <td>38</td>\n",
       "      <td>[map, merger, tool, tested, arcmap, written, r...</td>\n",
       "      <td>[(map, merger), (merger, tool), (tool, tested)...</td>\n",
       "      <td>[(map, merger, tool), (merger, tool, tested), ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>wellio.js\\nJavaScript for converting well-log ...</td>\n",
       "      <td>welliojs javascript converting welllog standar...</td>\n",
       "      <td>1053</td>\n",
       "      <td>[welliojs, javascript, converting, welllog, st...</td>\n",
       "      <td>[(welliojs, javascript), (javascript, converti...</td>\n",
       "      <td>[(welliojs, javascript, converting), (javascri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>geomodel-2-3dweb\\n\\nGenerates 3D web versions ...</td>\n",
       "      <td>geomodeldweb generates d web version geologica...</td>\n",
       "      <td>152</td>\n",
       "      <td>[geomodeldweb, generatesweb, version, geologic...</td>\n",
       "      <td>[(geomodeldweb, generates), (generates, d), (d...</td>\n",
       "      <td>[(geomodeldweb, generates, d), (generates, d, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>GeoFeature\\nGeological features of the Quanfoc...</td>\n",
       "      <td>geofeature geological feature quanfock hill de...</td>\n",
       "      <td>166</td>\n",
       "      <td>[geofeature, geological, feature, quanfock, hi...</td>\n",
       "      <td>[(geofeature, geological), (geological, featur...</td>\n",
       "      <td>[(geofeature, geological, feature), (geologica...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>U.S. Geological Survey Best Practices\\nThis re...</td>\n",
       "      <td>u geological survey best practice repository h...</td>\n",
       "      <td>13</td>\n",
       "      <td>[u, geological, survey, best, practice, reposi...</td>\n",
       "      <td>[(u, geological), (geological, survey), (surve...</td>\n",
       "      <td>[(u, geological, survey), (geological, survey,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           language                                            content  \\\n",
       "0            Python  Map Merger tool - tested using ArcMap 10.7\\nWr...   \n",
       "1  Jupyter Notebook  wellio.js\\nJavaScript for converting well-log ...   \n",
       "2            Python  geomodel-2-3dweb\\n\\nGenerates 3D web versions ...   \n",
       "3        JavaScript  GeoFeature\\nGeological features of the Quanfoc...   \n",
       "4        JavaScript  U.S. Geological Survey Best Practices\\nThis re...   \n",
       "\n",
       "                                       content_clean  doc_length  \\\n",
       "0  map merger tool tested arcmap written ryan cro...          38   \n",
       "1  welliojs javascript converting welllog standar...        1053   \n",
       "2  geomodeldweb generates d web version geologica...         152   \n",
       "3  geofeature geological feature quanfock hill de...         166   \n",
       "4  u geological survey best practice repository h...          13   \n",
       "\n",
       "                                               words  \\\n",
       "0  [map, merger, tool, tested, arcmap, written, r...   \n",
       "1  [welliojs, javascript, converting, welllog, st...   \n",
       "2  [geomodeldweb, generatesweb, version, geologic...   \n",
       "3  [geofeature, geological, feature, quanfock, hi...   \n",
       "4  [u, geological, survey, best, practice, reposi...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(map, merger), (merger, tool), (tool, tested)...   \n",
       "1  [(welliojs, javascript), (javascript, converti...   \n",
       "2  [(geomodeldweb, generates), (generates, d), (d...   \n",
       "3  [(geofeature, geological), (geological, featur...   \n",
       "4  [(u, geological), (geological, survey), (surve...   \n",
       "\n",
       "                                            trigrams  Topic  \n",
       "0  [(map, merger, tool), (merger, tool, tested), ...      4  \n",
       "1  [(welliojs, javascript, converting), (javascri...      0  \n",
       "2  [(geomodeldweb, generates, d), (generates, d, ...      4  \n",
       "3  [(geofeature, geological, feature), (geologica...      2  \n",
       "4  [(u, geological, survey), (geological, survey,...      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = explore.nlp_topic_modeling(df, max_df = 0.8 , min_df = 2 , n_components = 5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    175\n",
       "1    144\n",
       "3     72\n",
       "4     71\n",
       "2     45\n",
       "Name: Topic, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
